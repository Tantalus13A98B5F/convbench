{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser('~/tvm/python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy running time: 0.001935\n",
      "Baseline: 3.140241\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "import tvm.testing\n",
    "from tvm import te\n",
    "import numpy\n",
    "import timeit\n",
    "\n",
    "# The size of the matrix\n",
    "# (M, K) x (K, N)\n",
    "# You are free to try out different shapes, sometimes TVM optimization outperforms numpy with MKL.\n",
    "M = 1024\n",
    "K = 1024\n",
    "N = 1024\n",
    "\n",
    "# The default tensor type in tvm\n",
    "dtype = \"float32\"\n",
    "\n",
    "# using Intel AVX2(Advanced Vector Extensions) ISA for SIMD\n",
    "# To get the best performance, please change the following line\n",
    "# to llvm -mcpu=core-avx2, or specific type of CPU you use\n",
    "target = \"llvm -mcpu=cascadelake\"\n",
    "ctx = tvm.context(target, 0)\n",
    "\n",
    "# Random generated tensor for testing\n",
    "a = tvm.nd.array(numpy.random.rand(M, K).astype(dtype), ctx)\n",
    "b = tvm.nd.array(numpy.random.rand(K, N).astype(dtype), ctx)\n",
    "\n",
    "np_repeat = 100\n",
    "np_runing_time = timeit.timeit(\n",
    "    setup=\"import numpy\\n\"\n",
    "    \"M = \" + str(M) + \"\\n\"\n",
    "    \"K = \" + str(K) + \"\\n\"\n",
    "    \"N = \" + str(N) + \"\\n\"\n",
    "    'dtype = \"float32\"\\n'\n",
    "    \"a = numpy.random.rand(M, K).astype(dtype)\\n\"\n",
    "    \"b = numpy.random.rand(K, N).astype(dtype)\\n\",\n",
    "    stmt=\"answer = numpy.dot(a, b)\",\n",
    "    number=np_repeat,\n",
    ")\n",
    "print(\"Numpy running time: %f\" % (np_runing_time / np_repeat))\n",
    "\n",
    "answer = numpy.dot(a.asnumpy(), b.asnumpy())\n",
    "\n",
    "# Algorithm\n",
    "k = te.reduce_axis((0, K), \"k\")\n",
    "A = te.placeholder((M, K), name=\"A\")\n",
    "B = te.placeholder((K, N), name=\"B\")\n",
    "C = te.compute((M, N), lambda x, y: te.sum(A[x, k] * B[k, y], axis=k), name=\"C\")\n",
    "\n",
    "# Default schedule\n",
    "s = te.create_schedule(C.op)\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), ctx)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.asnumpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=1)\n",
    "print(\"Baseline: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
      "  for (x: int32, 0, 1024) {\n",
      "    for (y: int32, 0, 1024) {\n",
      "      C_2[((x*1024) + y)] = 0f32\n",
      "      for (k: int32, 0, 1024) {\n",
      "        C_2[((x*1024) + y)] = ((float32*)C_2[((x*1024) + y)] + ((float32*)A_2[((x*1024) + k)]*(float32*)B_2[((k*1024) + y)]))\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt1: 0.069975\n"
     ]
    }
   ],
   "source": [
    "bn = 32\n",
    "s = te.create_schedule(C.op)\n",
    "\n",
    "# Blocking by loop tiling\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(k,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(k, factor=4)\n",
    "\n",
    "# Hoist reduction domain outside the blocking loop\n",
    "s[C].reorder(xo, yo, ko, xi, ki, yi)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), ctx)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.asnumpy(), answer, rtol=1e-5)\n",
    "\n",
    "# By simply tiling the loop 32x32, and hoisting ko, ki outside the blocking loops,\n",
    "# we can see big speedup compared with the baseline.\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=10)\n",
    "print(\"Opt1: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
      "  for (x.outer: int32, 0, 32) {\n",
      "    for (y.outer: int32, 0, 32) {\n",
      "      for (x.inner.init: int32, 0, 32) {\n",
      "        for (y.inner.init: int32, 0, 32) {\n",
      "          C_2[((((x.outer*32768) + (x.inner.init*1024)) + (y.outer*32)) + y.inner.init)] = 0f32\n",
      "        }\n",
      "      }\n",
      "      for (k.outer: int32, 0, 256) {\n",
      "        for (x.inner: int32, 0, 32) {\n",
      "          for (k.inner: int32, 0, 4) {\n",
      "            for (y.inner: int32, 0, 32) {\n",
      "              C_2[((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)) + y.inner)] = ((float32*)C_2[((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)) + y.inner)] + ((float32*)A_2[((((x.outer*32768) + (x.inner*1024)) + (k.outer*4)) + k.inner)]*(float32*)B_2[((((k.outer*4096) + (k.inner*1024)) + (y.outer*32)) + y.inner)]))\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt2: 0.054813\n"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(k,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(k, factor=4)\n",
    "\n",
    "s[C].reorder(xo, yo, ko, xi, ki, yi)\n",
    "\n",
    "# Vectorization\n",
    "s[C].vectorize(yi)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), ctx)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.asnumpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=10)\n",
    "print(\"Opt2: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
      "  for (x.outer: int32, 0, 32) {\n",
      "    for (y.outer: int32, 0, 32) {\n",
      "      for (x.inner.init: int32, 0, 32) {\n",
      "        C_2[ramp((((x.outer*32768) + (x.inner.init*1024)) + (y.outer*32)), 1, 32)] = broadcast(0f32, 32)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 256) {\n",
      "        for (x.inner: int32, 0, 32) {\n",
      "          for (k.inner: int32, 0, 4) {\n",
      "            C_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)] = ((float32x32*)C_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.inner*1024)) + (k.outer*4)) + k.inner)], 32)*(float32x32*)B_2[ramp((((k.outer*4096) + (k.inner*1024)) + (y.outer*32)), 1, 32)]))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt3: 0.054759\n"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(k,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(k, factor=4)\n",
    "\n",
    "# re-ordering\n",
    "s[C].reorder(xo, yo, ko, xi, ki, yi)\n",
    "s[C].vectorize(yi)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), ctx)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.asnumpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=10)\n",
    "print(\"Opt3: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
      "  for (x.outer: int32, 0, 32) {\n",
      "    for (y.outer: int32, 0, 32) {\n",
      "      for (x.inner.init: int32, 0, 32) {\n",
      "        C_2[ramp((((x.outer*32768) + (x.inner.init*1024)) + (y.outer*32)), 1, 32)] = broadcast(0f32, 32)\n",
      "      }\n",
      "      for (k.outer: int32, 0, 256) {\n",
      "        for (x.inner: int32, 0, 32) {\n",
      "          for (k.inner: int32, 0, 4) {\n",
      "            C_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)] = ((float32x32*)C_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.inner*1024)) + (k.outer*4)) + k.inner)], 32)*(float32x32*)B_2[ramp((((k.outer*4096) + (k.inner*1024)) + (y.outer*32)), 1, 32)]))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt4: 0.175738\n"
     ]
    }
   ],
   "source": [
    "# We have to re-write the algorithm slightly.\n",
    "packedB = te.compute((N / bn, K, bn), lambda x, y, z: B[y, x * bn + z], name=\"packedB\")\n",
    "C = te.compute(\n",
    "    (M, N),\n",
    "    lambda x, y: te.sum(A[x, k] * packedB[y // bn, k, tvm.tir.indexmod(y, bn)], axis=k),\n",
    "    name=\"C\",\n",
    ")\n",
    "\n",
    "s = te.create_schedule(C.op)\n",
    "\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(k,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(k, factor=4)\n",
    "\n",
    "s[C].reorder(xo, yo, ko, xi, ki, yi)\n",
    "s[C].vectorize(yi)\n",
    "\n",
    "x, y, z = s[packedB].op.axis\n",
    "s[packedB].vectorize(z)\n",
    "s[packedB].parallel(x)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), ctx)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.asnumpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=10)\n",
    "print(\"Opt4: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
      "  attr [packedB: Pointer(float32)] \"storage_scope\" = \"global\";\n",
      "  allocate(packedB, float32x32, [32768]) {\n",
      "    for (x: int32, 0, 32) \"parallel\" {\n",
      "      for (y: int32, 0, 1024) {\n",
      "        packedB[ramp(((x*32768) + (y*32)), 1, 32)] = (float32x32*)B_2[ramp(((y*1024) + (x*32)), 1, 32)]\n",
      "      }\n",
      "    }\n",
      "    for (x.outer: int32, 0, 32) {\n",
      "      for (y.outer: int32, 0, 32) {\n",
      "        for (x.inner.init: int32, 0, 32) {\n",
      "          C_2[ramp((((x.outer*32768) + (x.inner.init*1024)) + (y.outer*32)), 1, 32)] = broadcast(0f32, 32)\n",
      "        }\n",
      "        for (k.outer: int32, 0, 256) {\n",
      "          for (x.inner: int32, 0, 32) {\n",
      "            for (k.inner: int32, 0, 4) {\n",
      "              C_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)] = ((float32x32*)C_2[ramp((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.inner*1024)) + (k.outer*4)) + k.inner)], 32)*(float32x32*)packedB[ramp((((y.outer*32768) + (k.outer*128)) + (k.inner*32)), 1, 32)]))\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write cache for blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt5: 0.045211\n"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "\n",
    "# Allocate write cache\n",
    "CC = s.cache_write(C, \"global\")\n",
    "\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "\n",
    "# Write cache is computed at yo\n",
    "s[CC].compute_at(s[C], yo)\n",
    "\n",
    "# New inner axes\n",
    "xc, yc = s[CC].op.axis\n",
    "\n",
    "(k,) = s[CC].op.reduce_axis\n",
    "ko, ki = s[CC].split(k, factor=4)\n",
    "s[CC].reorder(ko, xc, ki, yc)\n",
    "s[CC].unroll(ki)\n",
    "s[CC].vectorize(yc)\n",
    "\n",
    "x, y, z = s[packedB].op.axis\n",
    "s[packedB].vectorize(z)\n",
    "s[packedB].parallel(x)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), ctx)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.asnumpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=10)\n",
    "print(\"Opt5: %f\" % evaluator(a, b, c).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
      "  attr [packedB: Pointer(float32)] \"storage_scope\" = \"global\";\n",
      "  allocate(packedB, float32x32, [32768]);\n",
      "  attr [C.global: Pointer(float32)] \"storage_scope\" = \"global\";\n",
      "  allocate(C.global, float32, [1024]) {\n",
      "    for (x: int32, 0, 32) \"parallel\" {\n",
      "      for (y: int32, 0, 1024) {\n",
      "        packedB[ramp(((x*32768) + (y*32)), 1, 32)] = (float32x32*)B_2[ramp(((y*1024) + (x*32)), 1, 32)]\n",
      "      }\n",
      "    }\n",
      "    for (x.outer: int32, 0, 32) {\n",
      "      for (y.outer: int32, 0, 32) {\n",
      "        for (x.c.init: int32, 0, 32) {\n",
      "          C.global[ramp((x.c.init*32), 1, 32)] = broadcast(0f32, 32)\n",
      "        }\n",
      "        for (k.outer: int32, 0, 256) {\n",
      "          for (x.c: int32, 0, 32) {\n",
      "            C.global[ramp((x.c*32), 1, 32)] = ((float32x32*)C.global[ramp((x.c*32), 1, 32)] + (broadcast((float32*)A_2[(((x.outer*32768) + (x.c*1024)) + (k.outer*4))], 32)*(float32x32*)packedB[ramp(((y.outer*32768) + (k.outer*128)), 1, 32)]))\n",
      "            C.global[ramp((x.c*32), 1, 32)] = ((float32x32*)C.global[ramp((x.c*32), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.c*1024)) + (k.outer*4)) + 1)], 32)*(float32x32*)packedB[ramp((((y.outer*32768) + (k.outer*128)) + 32), 1, 32)]))\n",
      "            C.global[ramp((x.c*32), 1, 32)] = ((float32x32*)C.global[ramp((x.c*32), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.c*1024)) + (k.outer*4)) + 2)], 32)*(float32x32*)packedB[ramp((((y.outer*32768) + (k.outer*128)) + 64), 1, 32)]))\n",
      "            C.global[ramp((x.c*32), 1, 32)] = ((float32x32*)C.global[ramp((x.c*32), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.c*1024)) + (k.outer*4)) + 3)], 32)*(float32x32*)packedB[ramp((((y.outer*32768) + (k.outer*128)) + 96), 1, 32)]))\n",
      "          }\n",
      "        }\n",
      "        for (x.inner: int32, 0, 32) {\n",
      "          for (y.inner: int32, 0, 32) {\n",
      "            C_2[((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)) + y.inner)] = (float32*)C.global[((x.inner*32) + y.inner)]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt6: 0.007546\n"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "\n",
    "CC = s.cache_write(C, \"global\")\n",
    "\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "\n",
    "s[CC].compute_at(s[C], yo)\n",
    "\n",
    "xc, yc = s[CC].op.axis\n",
    "\n",
    "(k,) = s[CC].op.reduce_axis\n",
    "ko, ki = s[CC].split(k, factor=4)\n",
    "s[CC].reorder(ko, xc, ki, yc)\n",
    "s[CC].unroll(ki)\n",
    "s[CC].vectorize(yc)\n",
    "\n",
    "# parallel\n",
    "s[C].parallel(xo)\n",
    "\n",
    "x, y, z = s[packedB].op.axis\n",
    "s[packedB].vectorize(z)\n",
    "s[packedB].parallel(x)\n",
    "\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "assert func\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), ctx)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.asnumpy(), answer, rtol=1e-5)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=50)\n",
    "opt6_time = evaluator(a, b, c).mean\n",
    "print(\"Opt6: %f\" % opt6_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {C: Buffer(C_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             A: Buffer(A_2: Pointer(float32), float32, [1024, 1024], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [1024, 1024], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
      "  attr [packedB: Pointer(float32)] \"storage_scope\" = \"global\";\n",
      "  allocate(packedB, float32x32, [32768]) {\n",
      "    for (x: int32, 0, 32) \"parallel\" {\n",
      "      for (y: int32, 0, 1024) {\n",
      "        packedB[ramp(((x*32768) + (y*32)), 1, 32)] = (float32x32*)B_2[ramp(((y*1024) + (x*32)), 1, 32)]\n",
      "      }\n",
      "    }\n",
      "    for (x.outer: int32, 0, 32) \"parallel\" {\n",
      "      attr [C.global: Pointer(float32)] \"storage_scope\" = \"global\";\n",
      "      allocate(C.global, float32, [1024]);\n",
      "      for (y.outer: int32, 0, 32) {\n",
      "        for (x.c.init: int32, 0, 32) {\n",
      "          C.global[ramp((x.c.init*32), 1, 32)] = broadcast(0f32, 32)\n",
      "        }\n",
      "        for (k.outer: int32, 0, 256) {\n",
      "          for (x.c: int32, 0, 32) {\n",
      "            C.global[ramp((x.c*32), 1, 32)] = ((float32x32*)C.global[ramp((x.c*32), 1, 32)] + (broadcast((float32*)A_2[(((x.outer*32768) + (x.c*1024)) + (k.outer*4))], 32)*(float32x32*)packedB[ramp(((y.outer*32768) + (k.outer*128)), 1, 32)]))\n",
      "            C.global[ramp((x.c*32), 1, 32)] = ((float32x32*)C.global[ramp((x.c*32), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.c*1024)) + (k.outer*4)) + 1)], 32)*(float32x32*)packedB[ramp((((y.outer*32768) + (k.outer*128)) + 32), 1, 32)]))\n",
      "            C.global[ramp((x.c*32), 1, 32)] = ((float32x32*)C.global[ramp((x.c*32), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.c*1024)) + (k.outer*4)) + 2)], 32)*(float32x32*)packedB[ramp((((y.outer*32768) + (k.outer*128)) + 64), 1, 32)]))\n",
      "            C.global[ramp((x.c*32), 1, 32)] = ((float32x32*)C.global[ramp((x.c*32), 1, 32)] + (broadcast((float32*)A_2[((((x.outer*32768) + (x.c*1024)) + (k.outer*4)) + 3)], 32)*(float32x32*)packedB[ramp((((y.outer*32768) + (k.outer*128)) + 96), 1, 32)]))\n",
      "          }\n",
      "        }\n",
      "        for (x.inner: int32, 0, 32) {\n",
      "          for (y.inner: int32, 0, 32) {\n",
      "            C_2[((((x.outer*32768) + (x.inner*1024)) + (y.outer*32)) + y.inner)] = (float32*)C.global[((x.inner*32) + y.inner)]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL Env",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
