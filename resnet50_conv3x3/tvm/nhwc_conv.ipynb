{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "import pandas as pd\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "TVMPATH = os.path.expanduser('~/tvm/python')\n",
    "if TVMPATH not in sys.path:\n",
    "    sys.path.append(TVMPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights():\n",
    "    tot = np.fromfile('../dat.bin', dtype=np.float32)\n",
    "    channs, idx = [], [0]\n",
    "    with open('../fmt.txt') as f:\n",
    "        for case in f:\n",
    "            if ' ' not in case: continue\n",
    "            ch, *_ = [int(i) for i in case.split()]\n",
    "            channs.append(ch)\n",
    "            idx.append(idx[-1] + ch**2 * 9)\n",
    "    split = np.split(tot, idx[1:-1])\n",
    "    return [np.moveaxis(it.reshape((c, c, 3, 3)), 1, -1)\n",
    "             for it, c in zip(split, channs)]\n",
    "\n",
    "weight_list = get_weights()\n",
    "wei = weight_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te, tir\n",
    "target = \"llvm -mcpu=cascadelake\"\n",
    "ctx = tvm.context(target, 0)\n",
    "vec = 16\n",
    "\n",
    "\n",
    "def idxsplit(idx, dim, *dim2):\n",
    "    if dim2:\n",
    "        idx, *lower = idxsplit(idx, *dim2)\n",
    "    else:\n",
    "        lower = []\n",
    "    return (idx // dim, idx % dim, *lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1727696005"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chann, *_ = wei.shape\n",
    "hw = 64 * 256 // chann\n",
    "nbatch = 10\n",
    "data = np.random.randint(0, 256, (nbatch, hw, hw, chann)).astype('float32')\n",
    "\n",
    "# create compute\n",
    "\n",
    "A = te.placeholder((nbatch, hw, hw, chann), name='A')\n",
    "\n",
    "def im2col_kernel(row, col):\n",
    "    jn, jh, jw = idxsplit(row, hw, hw)\n",
    "    kh, kw, jc = idxsplit(col, 3, chann)\n",
    "    ih, iw = jh + kh - 1, jw + kw - 1\n",
    "    return tir.if_then_else(\n",
    "        tir.all(0 <= ih, ih < hw, 0 <= iw, iw < hw),\n",
    "        A[jn, ih, iw, jc], 0)\n",
    "\n",
    "outshape = (nbatch*hw*hw, chann*9)\n",
    "B = te.compute(outshape, im2col_kernel, name='B')\n",
    "\n",
    "# create schedule & func\n",
    "\n",
    "def im2col_schedule(C):\n",
    "    s = te.create_schedule(C.op)\n",
    "    _, bcdim = s[C].op.axis\n",
    "    _, bcd2 = s[C].split(bcdim, factor=chann)\n",
    "    s[C].vectorize(bcd2)\n",
    "    return s\n",
    "\n",
    "s = im2col_schedule(B)\n",
    "func = tvm.build(s, [A, B], target=target, name='im2col')\n",
    "\n",
    "# call func\n",
    "a = tvm.nd.array(data, ctx)\n",
    "b = tvm.nd.array(np.zeros(outshape, dtype='float32'), ctx)\n",
    "func(a, b)\n",
    "im2col = b.asnumpy()\n",
    "\n",
    "# evaluate func\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=10)\n",
    "evaluator(a, b).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164905199999999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dense\n",
    "wei2 = wei.reshape((chann, -1))\n",
    "M, K = im2col.shape\n",
    "N, _ = wei2.shape\n",
    "A = te.placeholder((M, K), name='A')\n",
    "B = te.placeholder((N, K), name='B')\n",
    "k = te.reduce_axis((0, K // vec), name='k')\n",
    "CC = te.compute((M, N, vec),\n",
    "                lambda m, n, z: te.sum(A[m, k*vec + z] * B[n, k*vec + z], axis=k), name='CC')\n",
    "kk = te.reduce_axis((0, vec), name='kk')\n",
    "C = te.compute((M, N), lambda m, n: te.sum(CC[m, n, kk], axis=kk), name='C')\n",
    "\n",
    "def create_dense_schedule(C):\n",
    "    s = te.create_schedule(C.op)\n",
    "    x, y = s[C].op.axis\n",
    "    (kk,) = s[C].op.reduce_axis\n",
    "    xo, yo, xi, yi = s[C].tile(x, y, 16, 8)\n",
    "    s[C].unroll(kk)\n",
    "    \n",
    "    (CC,) = s[C].op.input_tensors\n",
    "    s[CC].compute_at(s[C], yo)\n",
    "    x, y, z = s[CC].op.axis\n",
    "    (k,) = s[CC].op.reduce_axis\n",
    "    ko, ki = s[CC].split(k, factor=4)\n",
    "    s[CC].reorder(ko, x, y, ki, z)\n",
    "    s[CC].vectorize(z)\n",
    "    s[CC].unroll(ki)\n",
    "    return s\n",
    "\n",
    "s = create_dense_schedule(C)\n",
    "func = tvm.build(s, [A, B, C], target=target, name='dense')\n",
    "\n",
    "a = tvm.nd.array(im2col, ctx)\n",
    "b = tvm.nd.array(wei2, ctx)\n",
    "c = tvm.nd.array(np.zeros((M, N), dtype='float32'), ctx)\n",
    "func(a, b, c)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=1, repeat=20)\n",
    "#evaluator(a, b, c).mean\n",
    "pd.Series(evaluator(a, b, c).results).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尴尬，NHWC是$data \\times weight$，CSR还真没法利用向量化。整体转置吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSR\n",
    "wvals = np.abs(wei2.reshape((-1,)))\n",
    "wvals.sort()\n",
    "thres = wvals[int(0.5 * len(wvals))]\n",
    "spwei = scipy.sparse.csr_matrix(np.where(np.abs(wei2) < thres, 0, wei2))\n",
    "cntvals = spwei.data.size\n",
    "im2row = im2col.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3932800525"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = te.placeholder((K, M), name='Data')\n",
    "Wdat = te.placeholder((cntvals,), name='Wdat')\n",
    "Wind = te.placeholder((cntvals,), name='Wind', dtype='int')\n",
    "Wptr = te.placeholder((N+1,), name='Wptr', dtype='int')\n",
    "\n",
    "def csr_dense_kernel(wrow, drow):\n",
    "    row_start, row_end = Wptr[wrow], Wptr[wrow+1]\n",
    "    elem_idx = te.reduce_axis((0, row_end - row_start), name='elem_idx')\n",
    "    elem = row_start + elem_idx\n",
    "    return te.sum(Data[Wind[elem], drow] * Wdat[elem], axis=elem_idx)\n",
    "\n",
    "C = te.compute((N, M), csr_dense_kernel, name='C')\n",
    "\n",
    "def csr_dense_schedule(C):\n",
    "    s = te.create_schedule(C.op)\n",
    "    ckk, nhw = s[C].op.axis\n",
    "    (ei,) = s[C].op.reduce_axis\n",
    "    no, ni = s[C].split(nhw, factor=32)\n",
    "    s[C].reorder(ckk, no, ei, ni)\n",
    "    s[C].vectorize(ni)\n",
    "    return s\n",
    "\n",
    "s = csr_dense_schedule(C)\n",
    "func = tvm.build(s, [Data, Wdat, Wind, Wptr, C], target=target, name='csr_dense')\n",
    "\n",
    "data = tvm.nd.array(im2row, ctx)\n",
    "wdat = tvm.nd.array(spwei.data, ctx)\n",
    "wind = tvm.nd.array(spwei.indices, ctx)\n",
    "wptr = tvm.nd.array(spwei.indptr, ctx)\n",
    "ret = tvm.nd.array(np.zeros((N, M), dtype='float32'), ctx)\n",
    "func(data, wdat, wind, wptr, ret)\n",
    "\n",
    "evaluator = func.time_evaluator(func.entry_name, ctx, number=1, repeat=2)\n",
    "pd.Series(evaluator(data, wdat, wind, wptr, ret).results).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来需要一种新的稀疏储存格式，若干行为一段储存，每段内部按列储存。这样A的连续若干行在迭代时只需要做一轮B的行遍历。\n",
    "\n",
    "一种分段的CSC储存方式？\n",
    "\n",
    "啊哈哈好像不行。TVM做不了随机写入，CSC类的方案都有问题。只能像之前的方案那样做全对齐。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(Data_1: handle, Wdat_1: handle, Wind_1: handle, Wptr_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {Data: Buffer(Data_2: Pointer(float32), float32, [576, 655360], []),\n",
      "             Wptr: Buffer(Wptr_2: Pointer(int32), int32, [65], []),\n",
      "             Wind: Buffer(Wind_2: Pointer(int32), int32, [18432], []),\n",
      "             C: Buffer(C_2: Pointer(float32), float32, [64, 655360], []),\n",
      "             Wdat: Buffer(Wdat_2: Pointer(float32), float32, [18432], [])}\n",
      "  buffer_map = {Wptr_1: Wptr, Wdat_1: Wdat, C_1: C, Data_1: Data, Wind_1: Wind} {\n",
      "  for (wrow: int32, 0, 64) {\n",
      "    for (drow.outer: int32, 0, 20480) {\n",
      "      C_2[ramp(((wrow*655360) + (drow.outer*32)), 1, 32)] = broadcast(0f32, 32)\n",
      "      for (elem_idx: int32, 0, ((int32*)Wptr_2[(wrow + 1)] - (int32*)Wptr_2[wrow])) {\n",
      "        C_2[ramp(((wrow*655360) + (drow.outer*32)), 1, 32)] = ((float32x32*)C_2[ramp(((wrow*655360) + (drow.outer*32)), 1, 32)] + ((float32x32*)Data_2[ramp((((int32*)Wind_2[((int32*)Wptr_2[wrow] + elem_idx)]*655360) + (drow.outer*32)), 1, 32)]*broadcast((float32*)Wdat_2[((int32*)Wptr_2[wrow] + elem_idx)], 32)))\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [Data, Wdat, Wind, Wptr, C]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL Env",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
