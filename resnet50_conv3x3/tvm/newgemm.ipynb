{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Automatic calling is: Smart\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "%autocall\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te, tir\n",
    "# llc --version\n",
    "target = \"llvm -mcpu=znver2\"  # cascadelake\n",
    "ctx = tvm.context(target, 0)\n",
    "vec = 8\n",
    "\n",
    "\n",
    "def idxsplit(idx, dim, *dim2):\n",
    "    if dim2:\n",
    "        idx, *lower = idxsplit(idx, *dim2)\n",
    "    else:\n",
    "        lower = []\n",
    "    return (idx // dim, idx % dim, *lower)\n",
    "\n",
    "\n",
    "class TVMRunner:\n",
    "    def __init__(self, name, params):\n",
    "        self.name = name\n",
    "        self.params = params\n",
    "    \n",
    "    def lower(self):\n",
    "        return tvm.lower(*self.params, simple_mode=True)\n",
    "    \n",
    "    def _wrap_args(self, args):\n",
    "        def _wrap_single(item, item2):\n",
    "            if isinstance(item, np.ndarray):\n",
    "                return tvm.nd.array(item, ctx)\n",
    "            elif isinstance(item, type):\n",
    "                shape = [it.value for it in item2.shape]\n",
    "                return tvm.nd.array(np.zeros(shape, dtype=item), ctx)\n",
    "            else:\n",
    "                raise Exception('unknown arg', item)\n",
    "\n",
    "        _, args2 = self.params\n",
    "        realargs = [_wrap_single(it, it2) for it, it2 in zip(args, args2)]\n",
    "        return realargs\n",
    "    \n",
    "    def __call__(self, *args):\n",
    "        func = tvm.build(*self.params, target=target, name=self.name)\n",
    "        realargs = self._wrap_args(args)\n",
    "        func(*realargs)\n",
    "        return realargs\n",
    "    \n",
    "    def time_eval(self, *args, number=10):\n",
    "        func = tvm.build(*self.params, target=target, name=self.name)\n",
    "        realargs = self._wrap_args(args)\n",
    "        evaluator = func.time_evaluator(func.entry_name, ctx, number=number)\n",
    "        print(evaluator(*realargs).mean)\n",
    "        return realargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_oihw = np.random.rand(64, 64, 3, 3).astype('float32')\n",
    "weight_ohwi = np.moveaxis(weight_oihw, 1, -1)\n",
    "weight_ohwi_flat = weight_ohwi.reshape((weight_ohwi.shape[0], -1))\n",
    "nchw_data = np.random.randint(0, 256, (10, 64, 256, 256)).astype('float32')\n",
    "nhwc_data = np.moveaxis(nchw_data, 1, -1)\n",
    "\n",
    "del weight_oihw\n",
    "del weight_ohwi\n",
    "del nchw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bsr_sparse(dense, sprate, blocksize):\n",
    "    bsrdata = scipy.sparse.bsr_matrix(dense, blocksize=blocksize)\n",
    "    # find partition value\n",
    "    summed = bsrdata.data.sum((1, 2))\n",
    "    idx = int(sprate * len(summed) + 0.5)\n",
    "    val = np.partition(summed, idx)[idx]\n",
    "    # filter the data\n",
    "    data, indices, indptr, bsrWid = [], [], [], bsrdata.indptr[1]\n",
    "    for idx, (block, indval) in enumerate(zip(bsrdata.data, bsrdata.indices)):\n",
    "        if idx % bsrWid == 0:\n",
    "            indptr.append(len(data))\n",
    "        if block.sum() >= val:\n",
    "            data.append(block)\n",
    "            indices.append(indval)\n",
    "    indptr.append(len(data))\n",
    "    # convert format\n",
    "    bsrdata2 = tuple([np.array(i) for i in [data, indices, indptr]])\n",
    "    return scipy.sparse.bsr_matrix(bsrdata2, shape=dense.shape)\n",
    "\n",
    "\n",
    "def unpack_bsr(bsrdata):\n",
    "    return bsrdata.data, bsrdata.indices, bsrdata.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18924946\n"
     ]
    }
   ],
   "source": [
    "def create_nhwc_im2col(data):\n",
    "    N, H, W, C = inshape = data.shape\n",
    "    A = te.placeholder(inshape, name='A')\n",
    "\n",
    "    def im2col_kernel(row, col):\n",
    "        jn, jh, jw = idxsplit(row, H, W)\n",
    "        kh, kw, jc = idxsplit(col, 3, C)\n",
    "        ih, iw = jh + kh - 1, jw + kw - 1\n",
    "        return tir.if_then_else(\n",
    "            tir.all(0 <= ih, ih < H, 0 <= iw, iw < W),\n",
    "            A[jn, ih, iw, jc], 0)\n",
    "\n",
    "    outshape = (N*H*W, 9*C)\n",
    "    B = te.compute(outshape, im2col_kernel, name='B')\n",
    "\n",
    "    def im2col_schedule(CC):\n",
    "        s = te.create_schedule(CC.op)\n",
    "        _, coldim = s[CC].op.axis\n",
    "        _, chandim = s[CC].split(coldim, factor=C)\n",
    "        s[CC].vectorize(chandim)\n",
    "        return s\n",
    "    \n",
    "    s = im2col_schedule(B)\n",
    "    return s, [A, B]\n",
    "\n",
    "\n",
    "tr = TVMRunner('im2col', create_nhwc_im2col(nhwc_data))\n",
    "_, ret = tr.time_eval(nhwc_data, np.float32)\n",
    "nhwkkc_data = ret.asnumpy()\n",
    "kkcnhw_data = nhwkkc_data.T\n",
    "del ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Trans GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit nhwkkc_data @ weight_ohwi_flat.T\n",
    "#%timeit np.tensordot(nhwkkc_data, weight_ohwi_flat, [[1], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(A_1: handle, B_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {C: Buffer(C_2: Pointer(float32), float32, [655360, 64], []),\n",
      "             A: Buffer(A_2: Pointer(float32), float32, [655360, 576], []),\n",
      "             B: Buffer(B_2: Pointer(float32), float32, [64, 576], [])}\n",
      "  buffer_map = {A_1: A, B_1: B, C_1: C} {\n",
      "  attr [CC: Pointer(float32)] \"storage_scope\" = \"global\";\n",
      "  allocate(CC, float32, [1024]);\n",
      "  for (m.outer: int32, 0, 40960) {\n",
      "    for (n.outer: int32, 0, 8) {\n",
      "      for (m.init: int32, 0, 16) {\n",
      "        for (n.init: int32, 0, 8) {\n",
      "          CC[ramp(((m.init*64) + (n.init*8)), 1, 8)] = broadcast(0f32, 8)\n",
      "        }\n",
      "      }\n",
      "      for (kk.outer: int32, 0, 18) {\n",
      "        for (m: int32, 0, 16) {\n",
      "          for (n: int32, 0, 8) {\n",
      "            CC[ramp(((m*64) + (n*8)), 1, 8)] = ((float32x8*)CC[ramp(((m*64) + (n*8)), 1, 8)] + ((float32x8*)A_2[ramp((((m.outer*9216) + (m*576)) + (kk.outer*32)), 1, 8)]*(float32x8*)B_2[ramp((((n.outer*4608) + (n*576)) + (kk.outer*32)), 1, 8)]))\n",
      "            CC[ramp(((m*64) + (n*8)), 1, 8)] = ((float32x8*)CC[ramp(((m*64) + (n*8)), 1, 8)] + ((float32x8*)A_2[ramp(((((m.outer*9216) + (m*576)) + (kk.outer*32)) + 8), 1, 8)]*(float32x8*)B_2[ramp(((((n.outer*4608) + (n*576)) + (kk.outer*32)) + 8), 1, 8)]))\n",
      "            CC[ramp(((m*64) + (n*8)), 1, 8)] = ((float32x8*)CC[ramp(((m*64) + (n*8)), 1, 8)] + ((float32x8*)A_2[ramp(((((m.outer*9216) + (m*576)) + (kk.outer*32)) + 16), 1, 8)]*(float32x8*)B_2[ramp(((((n.outer*4608) + (n*576)) + (kk.outer*32)) + 16), 1, 8)]))\n",
      "            CC[ramp(((m*64) + (n*8)), 1, 8)] = ((float32x8*)CC[ramp(((m*64) + (n*8)), 1, 8)] + ((float32x8*)A_2[ramp(((((m.outer*9216) + (m*576)) + (kk.outer*32)) + 24), 1, 8)]*(float32x8*)B_2[ramp(((((n.outer*4608) + (n*576)) + (kk.outer*32)) + 24), 1, 8)]))\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      for (m.inner: int32, 0, 16) {\n",
      "        for (n.inner: int32, 0, 8) {\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = 0f32\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = ((float32*)C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] + (float32*)CC[((m.inner*64) + (n.inner*8))])\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = ((float32*)C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] + (float32*)CC[(((m.inner*64) + (n.inner*8)) + 1)])\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = ((float32*)C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] + (float32*)CC[(((m.inner*64) + (n.inner*8)) + 2)])\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = ((float32*)C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] + (float32*)CC[(((m.inner*64) + (n.inner*8)) + 3)])\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = ((float32*)C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] + (float32*)CC[(((m.inner*64) + (n.inner*8)) + 4)])\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = ((float32*)C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] + (float32*)CC[(((m.inner*64) + (n.inner*8)) + 5)])\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = ((float32*)C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] + (float32*)CC[(((m.inner*64) + (n.inner*8)) + 6)])\n",
      "          C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] = ((float32*)C_2[((((m.outer*1024) + (m.inner*64)) + (n.outer*8)) + n.inner)] + (float32*)CC[(((m.inner*64) + (n.inner*8)) + 7)])\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "0.66749248\n"
     ]
    }
   ],
   "source": [
    "def create_dense_trans_gemm(data, weight):\n",
    "    M, K, N, _ = *data.shape, *weight.shape\n",
    "    A = te.placeholder((M, K), name='A')\n",
    "    B = te.placeholder((N, K), name='B')\n",
    "    kk = te.reduce_axis((0, K // vec), name='kk')\n",
    "    CC = te.compute((M, N, vec),\n",
    "                    lambda m, n, v: te.sum(A[m, kk*vec + v] * B[n, kk*vec + v], axis=kk), name='CC')\n",
    "    kv = te.reduce_axis((0, vec), name='kv')\n",
    "    C = te.compute((M, N), lambda m, n: te.sum(CC[m, n, kv], axis=kv), name='C')\n",
    "\n",
    "    def create_dense_schedule(C, CC):\n",
    "        s = te.create_schedule(C.op)\n",
    "        m, n = s[C].op.axis\n",
    "        (kv,) = s[C].op.reduce_axis\n",
    "        mo, no, mi, ni = s[C].tile(m, n, 16, 8)\n",
    "        s[C].unroll(kv)\n",
    "\n",
    "        s[CC].compute_at(s[C], no)\n",
    "        mi, ni, v = s[CC].op.axis\n",
    "        (kk,) = s[CC].op.reduce_axis\n",
    "        ko, ki = s[CC].split(kk, factor=4)\n",
    "        s[CC].reorder(ko, mi, ni, ki, v)\n",
    "        s[CC].vectorize(v)\n",
    "        s[CC].unroll(ki)\n",
    "        return s\n",
    "\n",
    "    s = create_dense_schedule(C, CC)\n",
    "    return s, [A, B, C]\n",
    "\n",
    "\n",
    "tr = TVMRunner('dense_trans_gemm', create_dense_trans_gemm(nhwkkc_data, weight_ohwi_flat))\n",
    "print(tr.lower())\n",
    "tr.time_eval(nhwkkc_data, weight_ohwi_flat, np.float32)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse NonTrans GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsr_2x1 = make_bsr_sparse(weight_ohwi_flat, 0.5, (2, 1))\n",
    "#%timeit bsr_2x1 * kkcnhw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(Wdat_1: handle, Wind_1: handle, Wptr_1: handle, Data_1: handle, C_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {Wptr: Buffer(Wptr_2: Pointer(int32), int32, [33], []),\n",
      "             Wind: Buffer(Wind_2: Pointer(int32), int32, [9216], []),\n",
      "             Wdat: Buffer(Wdat_2: Pointer(float32), float32, [9216, 2, 1], []),\n",
      "             C: Buffer(C_2: Pointer(float32), float32, [64, 655360], []),\n",
      "             Data: Buffer(Data_2: Pointer(float32), float32, [576, 655360], [])}\n",
      "  buffer_map = {Wind_1: Wind, Data_1: Data, C_1: C, Wptr_1: Wptr, Wdat_1: Wdat} {\n",
      "  attr [CC: Pointer(float32x16)] \"storage_scope\" = \"global\";\n",
      "  allocate(CC, float32x16, [16]);\n",
      "  for (n.outer: int32, 0, 5120) {\n",
      "    for (m.outer: int32, 0, 32) {\n",
      "      for (dcol.outer.init: int32, 0, 8) {\n",
      "        CC[ramp((dcol.outer.init*16), 1, 16)] = broadcast(0f32, 16)\n",
      "        CC[ramp(((dcol.outer.init*16) + 128), 1, 16)] = broadcast(0f32, 16)\n",
      "      }\n",
      "      for (elem_idx: int32, 0, ((int32*)Wptr_2[(m.outer + 1)] - (int32*)Wptr_2[m.outer])) {\n",
      "        for (dcol.outer: int32, 0, 8) {\n",
      "          CC[ramp((dcol.outer*16), 1, 16)] = ((float32x16*)CC[ramp((dcol.outer*16), 1, 16)] + ((float32x16*)Data_2[ramp(((((int32*)Wind_2[((int32*)Wptr_2[m.outer] + elem_idx)]*655360) + (n.outer*128)) + (dcol.outer*16)), 1, 16)]*broadcast((float32*)Wdat_2[(((int32*)Wptr_2[m.outer]*2) + (elem_idx*2))], 16)))\n",
      "          CC[ramp(((dcol.outer*16) + 128), 1, 16)] = ((float32x16*)CC[ramp(((dcol.outer*16) + 128), 1, 16)] + ((float32x16*)Data_2[ramp(((((int32*)Wind_2[((int32*)Wptr_2[m.outer] + elem_idx)]*655360) + (n.outer*128)) + (dcol.outer*16)), 1, 16)]*broadcast((float32*)Wdat_2[((((int32*)Wptr_2[m.outer]*2) + (elem_idx*2)) + 1)], 16)))\n",
      "        }\n",
      "      }\n",
      "      for (n.inner.outer: int32, 0, 8) {\n",
      "        C_2[ramp((((m.outer*1310720) + (n.outer*128)) + (n.inner.outer*16)), 1, 16)] = broadcast(0f32, 16)\n",
      "        C_2[ramp((((m.outer*1310720) + (n.outer*128)) + (n.inner.outer*16)), 1, 16)] = ((float32x16*)C_2[ramp((((m.outer*1310720) + (n.outer*128)) + (n.inner.outer*16)), 1, 16)] + (float32x16*)CC[ramp((n.inner.outer*16), 1, 16)])\n",
      "        C_2[ramp(((((m.outer*1310720) + (n.outer*128)) + (n.inner.outer*16)) + 655360), 1, 16)] = broadcast(0f32, 16)\n",
      "        C_2[ramp(((((m.outer*1310720) + (n.outer*128)) + (n.inner.outer*16)) + 655360), 1, 16)] = ((float32x16*)C_2[ramp(((((m.outer*1310720) + (n.outer*128)) + (n.inner.outer*16)) + 655360), 1, 16)] + (float32x16*)CC[ramp(((n.inner.outer*16) + 128), 1, 16)])\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "1.0535100800000001\n"
     ]
    }
   ],
   "source": [
    "def create_nontrans_gemm(bsr, dense):\n",
    "    M, K, _, N, bsrR, bsrC = *bsr.shape, *dense.shape, *bsr.blocksize\n",
    "    bsrdata, bsrindices, bsrindptr = unpack_bsr(bsr)\n",
    "    Wdat = te.placeholder(bsrdata.shape, name='Wdat')\n",
    "    Wind = te.placeholder(bsrindices.shape, dtype='int', name='Wind')\n",
    "    Wptr = te.placeholder(bsrindptr.shape, dtype='int', name='Wptr')\n",
    "    Data = te.placeholder(dense.shape, name='Data')\n",
    "    \n",
    "    def bsr_gemm_kernel(wrow, brow, dcol, bcol):\n",
    "        row_start, row_end = Wptr[wrow], Wptr[wrow+1]\n",
    "        elem_idx = te.reduce_axis((0, row_end - row_start), name='elem_idx')\n",
    "        elem = row_start + elem_idx\n",
    "        return te.sum(Data[Wind[elem]*bsrC + bcol, dcol] * Wdat[elem, brow, bcol], axis=elem_idx)\n",
    "\n",
    "    CC = te.compute((M // bsrR, bsrR, N, bsrC), bsr_gemm_kernel, name='CC')\n",
    "    k = te.reduce_axis((0, bsrC), name='k')\n",
    "    C = te.compute((M, N), lambda m, n: te.sum(CC[m // bsrR, m % bsrR, n, k], axis=k), name='C')\n",
    "    \n",
    "    def create_bsr_gemm_schedule(C, CC):\n",
    "        s = te.create_schedule(C.op)\n",
    "        md, nd = s[C].op.axis\n",
    "        kd = s[C].op.reduce_axis[0]\n",
    "        md, nd1, rd, nd2 = s[C].tile(md, nd, bsrR, 16*vec)\n",
    "        s[C].reorder(nd1, md, nd2, rd, kd)\n",
    "        s[C].unroll(kd)\n",
    "        s[C].unroll(rd)\n",
    "        nd2a, nd2b = s[C].split(nd2, nparts=8)\n",
    "        s[C].vectorize(nd2b)\n",
    "        \n",
    "        s[CC].compute_at(s[C], md)\n",
    "        md, rd, nd2, cd = s[CC].op.axis\n",
    "        (ed,) = s[CC].op.reduce_axis\n",
    "        s[CC].reorder(md, ed, nd2, rd, cd)\n",
    "        s[CC].unroll(cd)\n",
    "        s[CC].unroll(rd)\n",
    "        nd2a, nd2b = s[CC].split(nd2, nparts=8)\n",
    "        s[CC].vectorize(nd2b)\n",
    "        return s\n",
    "    \n",
    "    s = create_bsr_gemm_schedule(C, CC)\n",
    "    return s, [Wdat, Wind, Wptr, Data, C]\n",
    "\n",
    "\n",
    "tr = TVMRunner('bsr_nontrans_gemm', create_nontrans_gemm(bsr_2x1, kkcnhw_data))\n",
    "print(tr.lower())\n",
    "tr.time_eval(*unpack_bsr(bsr_2x1), kkcnhw_data, np.float32)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Trans GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsr_1x2 = make_bsr_sparse(weight_ohwi_flat, 0.5, (2, 2))\n",
    "#%timeit nhwkkc_data * bsr_1x2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(Data_1: handle, Wdat_1: handle, Wind_1: handle, Wptr_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {Wind: Buffer(Wind_2: Pointer(int32), int32, [4608], []),\n",
      "             Wptr: Buffer(Wptr_2: Pointer(int32), int32, [33], []),\n",
      "             Data: Buffer(Data_2: Pointer(float32), float32, [655360, 576], []),\n",
      "             Wdat: Buffer(Wdat_2: Pointer(float32), float32, [4608, 2, 2], [])}\n",
      "  buffer_map = {Data_1: Data, Wdat_1: Wdat, Wind_1: Wind, Wptr_1: Wptr} {\n",
      "  attr [C: Pointer(float32x16)] \"storage_scope\" = \"global\";\n",
      "  allocate(C, float32x16, [2621440]);\n",
      "  attr [CC: Pointer(float32x16)] \"storage_scope\" = \"global\";\n",
      "  allocate(CC, float32x16, [32]);\n",
      "  for (m.outer: int32, 0, 5120) {\n",
      "    for (n.outer: int32, 0, 32) {\n",
      "      for (drow.outer: int32, 0, 8) {\n",
      "        CC[ramp((drow.outer*64), 4, 16)] = broadcast(0f32, 16)\n",
      "        CC[ramp(((drow.outer*64) + 1), 4, 16)] = broadcast(0f32, 16)\n",
      "        CC[ramp(((drow.outer*64) + 2), 4, 16)] = broadcast(0f32, 16)\n",
      "        CC[ramp(((drow.outer*64) + 3), 4, 16)] = broadcast(0f32, 16)\n",
      "        for (elem_idx: int32, 0, ((int32*)Wptr_2[(n.outer + 1)] - (int32*)Wptr_2[n.outer])) {\n",
      "          CC[ramp((drow.outer*64), 4, 16)] = ((float32x16*)CC[ramp((drow.outer*64), 4, 16)] + ((float32x16*)Data_2[ramp((((m.outer*73728) + (drow.outer*9216)) + ((int32*)Wind_2[((int32*)Wptr_2[n.outer] + elem_idx)]*2)), 576, 16)]*broadcast((float32*)Wdat_2[(((int32*)Wptr_2[n.outer]*4) + (elem_idx*4))], 16)))\n",
      "          CC[ramp(((drow.outer*64) + 1), 4, 16)] = ((float32x16*)CC[ramp(((drow.outer*64) + 1), 4, 16)] + ((float32x16*)Data_2[ramp(((((m.outer*73728) + (drow.outer*9216)) + ((int32*)Wind_2[((int32*)Wptr_2[n.outer] + elem_idx)]*2)) + 1), 576, 16)]*broadcast((float32*)Wdat_2[((((int32*)Wptr_2[n.outer]*4) + (elem_idx*4)) + 1)], 16)))\n",
      "          CC[ramp(((drow.outer*64) + 2), 4, 16)] = ((float32x16*)CC[ramp(((drow.outer*64) + 2), 4, 16)] + ((float32x16*)Data_2[ramp((((m.outer*73728) + (drow.outer*9216)) + ((int32*)Wind_2[((int32*)Wptr_2[n.outer] + elem_idx)]*2)), 576, 16)]*broadcast((float32*)Wdat_2[((((int32*)Wptr_2[n.outer]*4) + (elem_idx*4)) + 2)], 16)))\n",
      "          CC[ramp(((drow.outer*64) + 3), 4, 16)] = ((float32x16*)CC[ramp(((drow.outer*64) + 3), 4, 16)] + ((float32x16*)Data_2[ramp(((((m.outer*73728) + (drow.outer*9216)) + ((int32*)Wind_2[((int32*)Wptr_2[n.outer] + elem_idx)]*2)) + 1), 576, 16)]*broadcast((float32*)Wdat_2[((((int32*)Wptr_2[n.outer]*4) + (elem_idx*4)) + 3)], 16)))\n",
      "        }\n",
      "      }\n",
      "      for (m.inner.outer: int32, 0, 8) {\n",
      "        C[ramp((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)), 64, 16)] = broadcast(0f32, 16)\n",
      "        C[ramp((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)), 64, 16)] = ((float32x16*)C[ramp((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)), 64, 16)] + (float32x16*)CC[ramp((m.inner.outer*64), 4, 16)])\n",
      "        C[ramp((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)), 64, 16)] = ((float32x16*)C[ramp((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)), 64, 16)] + (float32x16*)CC[ramp(((m.inner.outer*64) + 1), 4, 16)])\n",
      "        C[ramp(((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)) + 1), 64, 16)] = broadcast(0f32, 16)\n",
      "        C[ramp(((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)) + 1), 64, 16)] = ((float32x16*)C[ramp(((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)) + 1), 64, 16)] + (float32x16*)CC[ramp(((m.inner.outer*64) + 2), 4, 16)])\n",
      "        C[ramp(((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)) + 1), 64, 16)] = ((float32x16*)C[ramp(((((m.outer*8192) + (m.inner.outer*1024)) + (n.outer*2)) + 1), 64, 16)] + (float32x16*)CC[ramp(((m.inner.outer*64) + 3), 4, 16)])\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "1.47607806\n"
     ]
    }
   ],
   "source": [
    "def create_trans_gemm(dense, bsr):\n",
    "    M, K, N, _, bsrR, bsrC = *dense.shape, *bsr.shape, *bsr.blocksize\n",
    "    bsrdata, bsrindices, bsrindptr = unpack_bsr(bsr)\n",
    "    Data = te.placeholder(dense.shape, name='Data')\n",
    "    Wdat = te.placeholder(bsrdata.shape, name='Wdat')\n",
    "    Wind = te.placeholder(bsrindices.shape, dtype='int', name='Wind')\n",
    "    Wptr = te.placeholder(bsrindptr.shape, dtype='int', name='Wptr')\n",
    "    \n",
    "    def bsr_gemm_kernel(drow, wrow, brow, bcol):\n",
    "        row_start, row_end = Wptr[wrow], Wptr[wrow+1]\n",
    "        elem_idx = te.reduce_axis((0, row_end - row_start), name='elem_idx')\n",
    "        elem = row_start + elem_idx\n",
    "        return te.sum(Data[drow, Wind[elem]*bsrC + bcol] * Wdat[elem, brow, bcol], axis=elem_idx)\n",
    "\n",
    "    CC = te.compute((M, N // bsrR, bsrR, bsrC), bsr_gemm_kernel, name='CC')\n",
    "    k = te.reduce_axis((0, bsrC), name='k')\n",
    "    C = te.compute((M, N), lambda m, n: te.sum(CC[m, n // bsrR, n % bsrR, k], axis=k), name='C')\n",
    "    \n",
    "    def create_bsr_gemm_schedule(C, CC):\n",
    "        s = te.create_schedule(C.op)\n",
    "        md, nd = s[C].op.axis\n",
    "        md1, nd, md2, rd = s[C].tile(md, nd, 16*vec, bsrR)\n",
    "        cd = s[C].op.reduce_axis[0]\n",
    "        s[C].unroll(cd)\n",
    "        s[C].unroll(rd)\n",
    "        md2a, md2b = s[C].split(md2, nparts=8)\n",
    "        s[C].vectorize(md2b)\n",
    "        \n",
    "        s[CC].compute_at(s[C], nd)\n",
    "        md2, nd0, rd, cd = s[CC].op.axis\n",
    "        md2a, md2b = s[CC].split(md2, nparts=8)\n",
    "        ed = s[CC].op.reduce_axis[0]\n",
    "        s[CC].reorder(nd0, md2a, ed, md2b, rd, cd)\n",
    "        s[CC].unroll(cd)\n",
    "        s[CC].unroll(rd)\n",
    "        s[CC].vectorize(md2b)\n",
    "        return s\n",
    "    \n",
    "    s = create_bsr_gemm_schedule(C, CC)\n",
    "    return s, [Data, Wdat, Wind, Wptr]\n",
    "\n",
    "\n",
    "tr = TVMRunner('bsr_trans_gemm', create_trans_gemm(nhwkkc_data, bsr_1x2))\n",
    "print(tr.lower())\n",
    "tr.time_eval(nhwkkc_data, *unpack_bsr(bsr_1x2), np.float32)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
